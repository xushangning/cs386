\documentclass[journal]{IEEEtran}


% correct bad hyphenation here
\hyphenation{op-tical net-works semi-conduc-tor}
\usepackage{amsmath}
\usepackage{comment}
\usepackage{booktabs}
\usepackage{subfigure}
\usepackage{xcolor}
\usepackage{listings}
\lstset{
  basicstyle=\fontsize{9}{10}\selectfont\ttfamily,
  numbers=left,
  numberstyle= \tiny,
  keywordstyle= \color{ blue!70},
  commentstyle= \color{red!50!green!50!blue!50},
  frame=single,
  rulesepcolor= \color{ red!20!green!20!blue!20} ,
  escapeinside=``,
  xleftmargin=1.5em,xrightmargin=0em, aboveskip=1em,
  framexleftmargin=2em,
  showstringspaces=false,
  showtabs=false,
  breaklines=true
}
\lstdefinelanguage{Solidity}
{
  morekeywords={contract, mapping, address, uint, private, function, public, if, payable},
  morecomment=[l]{//},
  morestring=[b]"
}


\usepackage{multicol}
\usepackage{lipsum}
\usepackage{mathtools}
\usepackage{cuted}

\usepackage{amsmath}
\usepackage{extpfeil}
\usepackage{mathpartir}
\usepackage[mathscr]{eucal}

\usepackage{hyperref}
\usepackage{cleveref}

\usepackage{CJK}

\crefformat{section}{\S#2#1#3} % see manual of cleveref, section 8.2.1
\crefformat{subsection}{\S#2#1#3}
\crefformat{subsubsection}{\S#2#1#3}

\begin{document}
%
% paper title
% Titles are generally capitalized except for words such as a, an, and, as,
% at, but, by, for, in, nor, of, on, or, the, to and up, which are usually
% not capitalized unless they are the first or last word of the title.
% Linebreaks \\ can be used within to get better formatting as desired.
% Do not put math or special symbols in the title.
\title{Bare Demo of IEEEtran.cls for Journals}
%
%
% author names and IEEE memberships
% note positions of commas and nonbreaking spaces ( ~ ) LaTeX will not break
% a structure at a ~ so this keeps an author's name from being broken across
% two lines.
% use \thanks{} to gain access to the first footnote area
% a separate \thanks must be used for each paragraph as LaTeX2e's \thanks
% was not built to handle multiple paragraphs
%

\author{
	Zhongye~Wang,~\IEEEmembership{SJTU,}
	Jingyu~Li,~\IEEEmembership{SJTU,}
	Xiaoyi~Bao,~\IEEEmembership{SJTU,}
	Shangning~Xu,~\IEEEmembership{SJTU,}
	and Chenxuan~Li,~\IEEEmembership{SJTU}
}

% The paper headers
\markboth{Journal of \LaTeX\ Class Files,~Vol.~13, No.~9, September~2014}%
{Shell \MakeLowercase{\textit{et al.}}: Bare Demo of IEEEtran.cls for Journals}
% The only time the second header will appear is for the odd numbered pages
% after the title page when using the twoside option.
%
% *** Note that you probably will NOT want to include the author's ***
% *** name in the headers of peer review papers.                   ***
% You can use \ifCLASSOPTIONpeerreview for conditional compilation here if
% you desire.


% make the title area
\maketitle

% As a general rule, do not put math, special symbols or citations
% in the abstract or keywords.
\begin{abstract}
The abstract goes here.
\end{abstract}

% Note that keywords are not normally used for peerreview papers.
\begin{IEEEkeywords}
IEEEtran, journal, \LaTeX, paper, template.
\end{IEEEkeywords}


\IEEEpeerreviewmaketitle



\section{Introduction}
\IEEEPARstart{T}{his}

\section{Related Work}
% lcx
\section{Subsampling and Interpolation}

\subsection{Subsampling}
Resampling using pixel area relation. Suppose $x\times y$ image subsampled down to size $x'\times y'$. scale\_x = x/x', scale\_y = y/y', and then we get block $scale\_x \times scale\_y$, block\_area = $scale\_x \times scale\_y$, the new image's each pixel is the weighted average of pixels in corresponding block's of the original image: 
\begin{align*}
	p'(x',y')=\sum_{i,j}{\frac{covered\_area \cdot p(i,j)}{block\_area}}
\end{align*}
i,j are nonnegative integers, $i \in [scale\_x\times x,scale\_x\times (x+1)]$ $j \in [scale\_y\times y,scale\_y\times (y+1)]$

\subsection{Interpolation}
In the mathematical field of numerical analysis, interpolation is a type of estimation, a method of constructing new data points within the range of a discrete set of known data points. In this project we use bilinear interpolation, bicubic interpolation, Lanczos resampling.

\subsubsection{Bilinear Interpolation}
\begin{figure}[h]
	\centering
	\includegraphics[width=0.6\linewidth]{fig/1.png}
	\label{fig:Bilinear Interpolation}
\end{figure}
\par First do linear interpolation in the x-direction:
\begin{align*}
p(R_1) = \frac{x_2-x}{x_2-x_1}\cdot p(Q_{11})+\frac{x-x_1}{x_2-x_1}\cdot p(Q_{21})\\
p(R_2) = \frac{x_2-x}{x_2-x_1}\cdot p(Q_{12})+\frac{x-x_1}{x_2-x_1}\cdot p(Q_{22})
\end{align*}
Then interpolate in the y-direction:
\begin{align*}
p(P) &= \frac{y2-y}{y2-y1}\cdot p(R_1)+\frac{y-y1}{y2-y1}\cdot p(R_2)\\ &=\small{\frac {1}{(x_{2}-x_{1})(y_{2}-y_{1})}}{\begin{bmatrix}x_{2}-x&x-x_{1}\end{bmatrix}}{\begin{bmatrix}f(Q_{11})&f(Q_{12})\\f(Q_{21})&f(Q_{22})\end{bmatrix}}{\begin{bmatrix}y_{2}-y\\y-y_{1}\end{bmatrix}}
\end{align*}
\par We can get the corresponding pixel's coordinate in original image: $x'\cdot scale\_x=x$, $y'\cdot scale\_y=y$. If either x or y is not integer, $x_1=int(x),x_2=int(x)+1,y_1=int(y), y_2=int(y)+1$, do interpolation.
\par This algorithm reduces some of the visual distortion caused by resizing an image to a non-integral zoom factor.
~\\
\subsubsection{Bicubic Interpolation}
~\\
\par In this method, new image’s pixel at point (x', y'), p(x',y'), is the weighted average of the nearest 16 points in the original image. An interpolator can be obtained by applying a convolution with the following kernel in both dimensions:
\begin{align*}
{\displaystyle W(x)={\begin{cases}(a+2)|x|^{3}-(a+3)|x|^{2}+1&{\text{for }}|x|\leq 1,\\a|x|^{3}-5a|x|^{2}+8a|x|-4a&{\text{for }}1<|x|<2,\\0&{\text{otherwise}},\end{cases}}}
\end{align*}
where a is usually set to −0.5 or −0.75.
\par $x'\cdot scale\_x=x$, $y'\cdot scale\_y=y$. If either x or y is not integer, $x_i$=int(x+i), $y_j$=int(y+j), i, j = -1,0,1,2:

do interpolation in the x-direction:
\begin{align*}
p(x',y_j)=\sum_{i}{W(x-x_i)\cdot p(x_i,y_j)}
\end{align*}
then do interpolation in the y-direction:
\begin{align*}
p(x',y')=\sum_{j}{W(y-y_j)\cdot p(x',y_j)} 
\end{align*}
\par Images resampled with bicubic interpolation are smoother and have fewer interpolation artifacts.
~\\
\subsubsection{Lanczos Resampling}
~\\
\par The effect of each input sample on the interpolated values is defined by the filter's reconstruction kernel L(x), called the Lanczos kernel. 
\begin{align*}
{\displaystyle L(x)={\begin{cases}\operatorname {sinc} (x)\,\operatorname {sinc} (x/a)&{\text{if}}\ -a<x<a,\\0&{\text{otherwise}}.\end{cases}}}
\end{align*}
Equivalently,
\begin{align*}
{\displaystyle L(x)={\begin{cases}1&{\text{if}}\ x=0,\\{\dfrac {a\sin(\pi x)\sin(\pi x/a)}{\pi ^{2}x^{2}}}&{\text{if}}\ -a\leq x<a\ {\text{and}}\ x\neq 0,\\0&{\text{otherwise}}.\end{cases}}}
\end{align*}
\par The parameter $a$ is a positive integer, typically 2 or 3 (but in opencv, the method is cv2.INTER$\_$LANCZOS4, $a$=4), which determines the size of the kernel. The Lanczos kernel has $2a-1$ labes:a positive one at the center, and $a-1$ alternating negative and positive lobes on each side.
\begin{align*}
L(x,y) &= L(x) \cdot L(y)\\
p(x',y') &= \sum_{i,j}{L(x_i-x)\cdot L(y_j-y)\cdot p(x_i,y_j)}
\end{align*}
$x_i=int(x+i)$, $y_j=int(y+j)$, $-a+1\leq i, j \leq a-1$

\section{Methodology}
In this section, we \dots

\subsection{A Naive Thought: Enumerative Search}
\cref{sec:enumerative}
We first try to tackle the problem with a very naive approach.
If we know all possible ways to generate false UHD images, assuming the number of them is limited, we can actually enumerate through all of them to determine which algorithm is applied in any given false UHD image.

We can do this by first subsampling a given image, then using every know algorithm to upsampling the downsampled image back to the original size.
Say the image is originally faked with algorithm A, then the reconstructed image using algorithm A should result in very small MSE wrt. to the original one.
If after enumerated all possible algorithms and subsampling rate (also assumed limited), no algorithm satisfy the above statement, then we can assert that the image is UHD.

The naive algorithm to determine the authenticity of an UHD image is however impractical, because we cannot enumerate all possible ways to fabricate false UHD images and upsampling rate.
The application of DNN in UHD image generation also makes such approach infeasible due to tremendous amount of hyper-parameters to it.

However, we can still refer to the idea of reconstruct a reference image by first subsampling then upsampling with some reference interpolation method.
If we use the most trivial interpolation method to generate the reference, for any given image, the more it improves from the reference, we are more confident that it is true UHD.
This idea gives birth to the relative DCT analysis we propose later.

\subsection{Relative DCT Analysis of UHD Images}
The are natural differences between real UHD images and fake UHD image generated with interpolation.
Real UHD images contains large amount of real objects, each with some random but distinct characteristics.
Therefore, if we use functions to fit pixel values in different regions, there should be very few similarities between those functions.
On the other hand, because it is often a common practice to use a single interpolation function to do upsampling to get fake UHD images, the functions in different regions should share certain similarities.
Some interpolation methods (like bicubic) would even result in same family of those functions.

Another idea is that, there are always noises in real UHD images due to the inherent deficiencies in equipments, whereas the fake UHD images undergoes a stage of subsampling, which eliminates some noises.
As a result, the fake UHD image should be more smooth than the original one.
We can use DCT to extract the magnitudes at different frequencies, and observe those for high frequencies is relatively lower in fake UHD images.

We goes with the latter approach, while the former one is more promising if we have efficient way to identify similarities between sampled values of functions.
Nevertheless, we need a way to extract features of those functions in both approaches, that is where discrete cosine transform (DCT) come into place.

\subsubsection{Relative DCT Analysis}
Different from traditional DCT analysis, we introduce the concept of relative DCT analysis based on the idea of reference image proposed in \ref{sec:enumerative}.
The DCT coefficients for the original image are given by \eqref{eq:dct}.
\begin{equation}
	\begin{array}{l}
		\mathcal{D}(u, v) = c(u)c(v)\sum_{x=0}^{N-1}\sum_{y=0}^{N-1}f(x, y)C(x, u)C(y, v)\\
		\vspace{-0.75em}\\
		\text{where } c(u) = \begin{cases}
			\sqrt{\frac{1}{N}} & u = 0 \\
			\sqrt{\frac{2}{N}} & u \neq 0
		\end{cases}, C(x, u) = \cos\bigg[\frac{(x+0.5)\pi}{N}u\bigg]
	\end{array}
	\label{eq:dct}
\end{equation}

We define the reference image $f'$ with downsampling rate $\alpha$ and upsampling method $p$ and its DCT coefficients $\mathcal{D}'$.
We then define the relative DCT transform in \eqref{eq:rel_dct}.
\begin{equation}
	\mathcal{D}_r(u, v) = \begin{cases}
		\frac{\mathcal{D}(u, v)}{\mathcal{D}'(u, v)} - 1 & \mathcal{D}'(u, v) \neq 0 \\
		\inf & \mathcal{D}'(u, v) = 0
	\end{cases}
	\label{eq:rel_dct}
\end{equation}
For any image, the relative DCT coefficients should give a fair criteria that is less sensitive to the content in the image.

\subsubsection{Tiled DCT Analysis} We also consider it more practical to apply DCT analysis on tiles of images instead of the entire one.
This is not only because it is faster and gives more stable and smaller DCT coefficients, but also due to the fact that the upsampling often considers only the region around the pixel to reconstruct.
For some tile width $T$, we define the $(i, j)$ tile of image in \eqref{eq:tile}.
\begin{equation}
	\begin{array}{l}
		f^{(i,j)}(x, y) = f(i * T + x, j * T + y), \\
		\vspace{-0.75em}\\
		\forall 0 \leq x, y < T, 0 \leq i, j < \min\{\lfloor\frac{W}{T}\rfloor, \lfloor\frac{H}{T}\rfloor\}
	\end{array}
	\label{eq:tile}
\end{equation}
We denote the relative DCT coefficients for the tile as $\mathcal{D}_r^{(i, j)}(u, v)$.

\section{Conclusion}
The conclusion goes here.






\bibliographystyle{IEEEtran}
\bibliography{Ref}


% that's all folks
\end{document}